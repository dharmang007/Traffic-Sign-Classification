{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:myenv] *",
      "language": "python",
      "name": "conda-env-myenv-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "transfer_final.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJtdRsVGZpku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from skimage import exposure\n",
        "from skimage.color import rgb2gray\n",
        "keras = tf.keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WSuRAJ8Zpk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.applications.resnet_v2.ResNet50V2(include_top=False, input_shape=(224,224,3), weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBFFFcAIZpk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(image):\n",
        "    gray = rgb2gray(image)\n",
        "    hist = exposure.equalize_hist(image)\n",
        "    return hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i5kM3mMZpk8",
        "colab_type": "code",
        "colab": {},
        "outputId": "40e1d513-dcb2-408b-8189-8004ae3d5644"
      },
      "source": [
        "%%time\n",
        "preprocessor = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess,\n",
        "                                                           validation_split=0.2)\n",
        "training_data = preprocessor.flow_from_directory(\"E:/Jupyter/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images/\",\n",
        "                                        target_size=(224, 224),\n",
        "                                       subset='training')\n",
        "val_data = preprocessor.flow_from_directory(\"E:/Jupyter/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images/\",\n",
        "                                        target_size=(224, 224),\n",
        "                                       subset='validation')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31368 images belonging to 43 classes.\n",
            "Found 7841 images belonging to 43 classes.\n",
            "Wall time: 1.92 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgx0GslaZplA",
        "colab_type": "code",
        "colab": {},
        "outputId": "d8bb808a-b81f-4316-bab9-b69fe15b4c85"
      },
      "source": [
        "%%time\n",
        "features = model(training_data[0][0])\n",
        "print(features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\skimage\\exposure\\exposure.py:181: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
            "  hist, bin_centers = histogram(image, nbins)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(32, 7, 7, 2048)\n",
            "Wall time: 2.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "235mYE3pZplC",
        "colab_type": "code",
        "colab": {},
        "outputId": "fd74fdc0-cd08-4728-b529-12a25fa40b65"
      },
      "source": [
        "model.trainable = False\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOyyOoaNZplE",
        "colab_type": "code",
        "colab": {},
        "outputId": "da74ba1a-88d3-4a83-ceb9-06a9f8b258dc"
      },
      "source": [
        "global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(features)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx_0_Wy8ZplG",
        "colab_type": "code",
        "colab": {},
        "outputId": "e82a1eb0-0656-43db-91a0-00bce09cf180"
      },
      "source": [
        "prediction_layer = keras.layers.Dense(43, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSUFUlfVZplH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assembled_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpc6HSL9ZplI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assembled_model.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgQ_OFukZplJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc8c87b8-e511-4b07-fc93-b386d3c61320"
      },
      "source": [
        "loss0,accuracy0 = assembled_model.evaluate(val_data, steps = 20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "20/20 [==============================] - 28s 1s/step - loss: 4.2424 - accuracy: 0.0453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mssDIi0zZplK",
        "colab_type": "code",
        "colab": {},
        "outputId": "957afff5-f98a-4f98-ec41-cea4db9fc1e4"
      },
      "source": [
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial loss: 4.24\n",
            "initial accuracy: 0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPigc73ZplL",
        "colab_type": "code",
        "colab": {},
        "outputId": "a1cf56c2-4c78-4948-b020-787cdd11e842"
      },
      "source": [
        "%%time\n",
        "history = assembled_model.fit(training_data,\n",
        "                    epochs=10,\n",
        "                    validation_data=val_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 981 steps, validate for 246 steps\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\skimage\\exposure\\exposure.py:181: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
            "  hist, bin_centers = histogram(image, nbins)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "981/981 [==============================] - 4281s 4s/step - loss: 1.9713 - accuracy: 0.4748 - val_loss: 2.5393 - val_accuracy: 0.3051\n",
            "Epoch 2/10\n",
            "981/981 [==============================] - 4272s 4s/step - loss: 1.0404 - accuracy: 0.7104 - val_loss: 2.8544 - val_accuracy: 0.3007\n",
            "Epoch 3/10\n",
            "981/981 [==============================] - 4273s 4s/step - loss: 0.7991 - accuracy: 0.7733 - val_loss: 3.0467 - val_accuracy: 0.3079\n",
            "Epoch 4/10\n",
            "981/981 [==============================] - 4276s 4s/step - loss: 0.6729 - accuracy: 0.8062 - val_loss: 3.2366 - val_accuracy: 0.3123\n",
            "Epoch 5/10\n",
            "981/981 [==============================] - 4278s 4s/step - loss: 0.5931 - accuracy: 0.8263 - val_loss: 3.3876 - val_accuracy: 0.3123\n",
            "Epoch 6/10\n",
            "981/981 [==============================] - 4272s 4s/step - loss: 0.5362 - accuracy: 0.8431 - val_loss: 3.5552 - val_accuracy: 0.3104\n",
            "Epoch 7/10\n",
            "981/981 [==============================] - 4273s 4s/step - loss: 0.4929 - accuracy: 0.8566 - val_loss: 3.6388 - val_accuracy: 0.3150\n",
            "Epoch 8/10\n",
            "981/981 [==============================] - 4424s 5s/step - loss: 0.4581 - accuracy: 0.8657 - val_loss: 3.7262 - val_accuracy: 0.3144\n",
            "Epoch 9/10\n",
            "981/981 [==============================] - 5186s 5s/step - loss: 0.4304 - accuracy: 0.8736 - val_loss: 3.9089 - val_accuracy: 0.3088\n",
            "Epoch 10/10\n",
            "981/981 [==============================] - 5405s 6s/step - loss: 0.4065 - accuracy: 0.8812 - val_loss: 4.0025 - val_accuracy: 0.3100\n",
            "Wall time: 12h 29min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmoTB02ZplM",
        "colab_type": "code",
        "colab": {},
        "outputId": "303a1e4f-6cb4-4a21-ec0d-b0419e087c13"
      },
      "source": [
        "assembled_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Model)           (None, 7, 7, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 43)                88107     \n",
            "=================================================================\n",
            "Total params: 23,652,907\n",
            "Trainable params: 88,107\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1-crTwyZplN",
        "colab_type": "code",
        "colab": {},
        "outputId": "32f5687f-4a60-43a2-8986-7496126b16ad"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFPeMjRwZplO",
        "colab_type": "text"
      },
      "source": [
        "Using Tensorflow Keras, transfer learning was implemented using a ResNetv2 50 pre-trained on Google's ImageNet image recognition dataset, sequentially layered with a global averaging layer and a prediction (output) layer. Output layer was one-hot encoded to 43 outputs, activation function was softmax, loss function was categorical cross-entropy, and optimization was Adam. Test data set was split into 80% test and 20% validation and shuffled. Initial loss and accuracy were 4.24 and 0.05, respectively. Training was done over two epochs because it takes around 3 hours for a single epoch to complete on dev platform. Final training loss and accuracy were 0.4065 and 0.8812, respectively. Final validation loss and accuracy were 4.0025 and 0.3100, respectively."
      ]
    }
  ]
}